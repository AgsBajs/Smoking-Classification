# Smoking Prediction with Logistic Regression  
**Using the Global Coffee Health Dataset (Kaggle)**  

## ðŸ“Œ Project Overview  
This project explores the relationship between lifestyle factors and smoking behavior using the [Global Coffee Health Dataset](https://www.kaggle.com/datasets/uom190346a/global-coffee-health-dataset/data). The primary goal was to build a predictive model to identify smokers based on demographic, lifestyle, and health-related features.  

We compared baseline models (Logistic Regression and Random Forest), tuned Logistic Regression, and explored the role of decision thresholds in balancing **precision** and **recall**.  

---

## ðŸ“Š Dataset Description  
The dataset contains **10,000 synthetic records** reflecting realistic correlations between coffee consumption, sleep, and health outcomes across 20 countries.  

### **Features**  
- **ID** *(int)* â†’ Unique record ID  
- **Age** *(int)* â†’ Participant age (18â€“80)  
- **Gender** *(cat)* â†’ Male, Female, Other  
- **Country** *(cat)* â†’ Country of residence (20 total)  
- **Coffee_Intake** *(float)* â†’ Cups of coffee per day (0â€“10)  
- **Caffeine_mg** *(float)* â†’ Estimated daily caffeine intake in mg  
- **Sleep_Hours** *(float)* â†’ Hours of sleep per night (3â€“10)  
- **Sleep_Quality** *(cat)* â†’ Poor, Fair, Good, Excellent  
- **BMI** *(float)* â†’ Body Mass Index (15â€“40)  
- **Heart_Rate** *(int)* â†’ Resting heart rate (50â€“110 bpm)  
- **Stress_Level** *(cat)* â†’ Low, Medium, High  
- **Physical_Activity_Hours** *(float)* â†’ Weekly physical activity (0â€“15 hours)  
- **Health_Issues** *(cat)* â†’ None, Mild, Moderate, Severe  
- **Occupation** *(cat)* â†’ Office, Healthcare, Student, Service, Other  
- **Smoking** *(bool)* â†’ Target variable (0 = No, 1 = Yes)  
- **Alcohol_Consumption** *(bool)* â†’ 0 = No, 1 = Yes  

---

## ðŸ”Ž Methodology  
1. **Preprocessing**  
   - Imputed missing values (median for numerics, most frequent for categoricals).  
   - Standardized numeric features.  
   - One-hot encoded categorical features.  

2. **Baseline Models**  
   - Logistic Regression  
   - Random Forest  
   - Observed poor performance from Random Forest due to high sparsity after one-hot encoding and class imbalance.  

3. **Model Tuning**  
   - GridSearchCV on Logistic Regression (`C`, penalty, solver).  
   - Chose **Logistic Regression with L2 penalty, C â‰ˆ 1.445, solver = liblinear**.  

4. **Threshold Tuning**  
   - Explored thresholds 0.3â€“0.7.  
   - Found **0.45** yielded the best trade-off:  
     - Precision â‰ˆ **0.201**  
     - Recall â‰ˆ **0.828**  
     - F1 Score â‰ˆ **0.323**  
   - ROC-AUC â‰ˆ 0.507 and PR-AUC â‰ˆ 0.208 show the dataset has weak signal for smoking prediction, but recall-focused thresholds enable screening.  

---

## ðŸ“ˆ Results  
- **Default (0.50 threshold)** â†’ Recall = 0.429, F1 = 0.274  
- **Chosen (0.45 threshold)** â†’ Recall = 0.828, F1 = 0.323  
- Confusion Matrix @ 0.45:  
